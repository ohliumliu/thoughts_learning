I was a little shocked when reading the Andrew Ng's lecture notes on the exponential family. Although some of the
terminologies obvious were generalized from statistical mechanics, it still seems a little magical to see the power of
exponential family. To me, this is a new way of thinking about a problem. This note is my attempt to understand
the rationale behine the definition and application of exponential family.

\section{The problem}
Suppose we attempt to study the relation between a feature $x$ and an observable $y$. In regression, one has to start with some kind of hypothesis $y=h(x; \theta)$. In reality, of course, $y$ is always a little different from the prediction of the hypothesis, or,
\begin{equation}
y_i = h(x_i;\theta) + \epsilon_i
\end{equation}
for a particular observation $(x_i, y_i)$. We would hope that $\epsilon_i\sim\mathrm{i.i.d}\ \mathcal{N}(0, \sigma^2)$.
In fact, this is not always the case, and it is highly recommended to inspect the residual after performing a regression.

Anyway, a more fundamental issue is the origin of the hypothesis. It could come from the underlying physical model. If we only utilize the nature of statistics, what can we say about the hypothesis? For example, sigmodal function is used to do classification analysis, but why is sigmodal favored by us among all the possible smooth approximation to the step function.

In many cases, we do know, with certain confidence, the distribution of observable $y$. For example, due to central limit theoreom, it is probably safe to assume that a continous observable is Gaussian if it reflects the combined/summed effect of many underlying processes. Another example is classification; we do know the sample could be either positive or negative following Bernoulli distribution. Given this information, the objective of regression analysis is to find the relation between the parameters of the distribution and the underlying features $x$. So, what can we say about this relationship in light of the presumed distribution of $y$? 

\section{Exponential family}
In the most general sense, $y$ is a randome variable following some distribution $\mathcal G(y, \eta)$. Here, $\eta$ represents the yet unknown contribution of features. The so called exponential family is a group of distribution that can be written in a way \emph{such that $\eta$ and $y$ can be factored in the exponential}:
\begin{eqnarray}
	\mathcal G(y, \eta) &\propto& b(y)e^{\eta y},\\
			 &=& b(y)e^{\eta y - a(\eta)}\label{eqn:exponential-family}
\end{eqnarray}
The second equation only adds a normalization term $e^{-a(\eta)}$ which is a function of $\eta$. $a(\eta)$ is called log partition function, because this idea originated from satistical physics. In particular, this is a generalization of Boltzman equation, if one relates $y$ to energy, and $\eta$ to $\beta\equiv 1/k_BT$. From a pratical point of view, the whole idea of partition function and Boltzman distribution is that moments of energy or $y$ can be calculated as the derivative of log partition function with respect to $\beta$ or $\eta$. In essense, $\beta$ or $\eta$ is the Lagrangian multiplier. In order to sastisfy this, the only coupling term in $\mathcal G(y, \eta)$ should be $e^{\eta y}$.

As an example, let's look at $\langle y\rangle$.
\begin{eqnarray}
	\langle y\rangle &=&\int y\mathcal G(y, \eta)\, dy\\
		   &=&\int b(y)e^{\eta y -a(\eta)}y\,dy\\
     &=&\int b(y)\frac{\partial}{\partial\eta}\left[e^{\eta y}e^{-a(\eta)}\right]\,dy + \int b(y)e^{\eta y-a(\eta)}\frac{\partial a(\eta)}{\partial\eta}\,dy\\
	&=&(\frac{\partial}{\partial\eta}+ \frac{\partial a(\eta)}{\partial\eta})\int \mathcal G(y, \eta)\, dy\\
	&=&\frac{\partial a(\eta)}{\partial\eta}.\label{eqn:average}
\end{eqnarray}

The exponential family is a generalization of Boltzman distriubtion because of the extra factor $b(y)$. This generalization doesn't affect the above property regarding partition function and expectation value.

Remember our motivation is to find out constraints on $\eta$ using only mathematical facts. We already have one. The derivative of log partition function is the expectation of $y$. That means, whatever model we choose to predict the distribution of $y$, if the distribution of $y$ is a member of the exponential family, then $\langle y\rangle=da(\eta)/d\eta$. The hypothesis $h(x, \theta)$ of course predicts the expectation of $y$, and it thus follows
\begin{equation}
	h(x, \theta) = \frac{d}{d\eta}a(\eta). \label{eqn:exponential_hypo}
\end{equation}

To reiterate, Eq.~\ref{eqn:exponential_hypo} tells us, if the distribution of $y$ belongs to the exponential family, our hypothesis must assume a form arising from the derivative of the log partition function. In another word, there could be various ways to get $\eta$ from $x$ and $\theta$, but the functional form of the hypothesis $h(x, \theta)$ is fixed if it's written in terms of $\eta$. Remember that $\eta$ is the proxy for our hypothesis regarding $x$ and $\theta$.

Eq.~\ref{eqn:exponential_hypo} only requires that the hypothesis agrees with the expected value of $y$. Being such a general requirement, what information can we extract from it?

\section{Gaussian}
Let's start with Gaussian and apply the idea of Eq.~\ref{eqn:exponential_hypo}. First, we try to rewrite a Gaussian distribution according to Eq.~\ref{eqn:exponential-family}.

\begin{eqnarray}
	\mathcal N(\mu, 1)&=&\frac{1}{\sqrt{2\pi}}\exp\{-(y-\mu)^2/2\},\\
		   &=&\frac{1}{\sqrt{2\pi}}e^{-y^2/2}e^{\mu y}e^{-\mu^2/2}.
\end{eqnarray}

Obviously, Gassusian distribution $\mathcal N(\mu, 1)$ is a member of the exponential family by setting
\begin{eqnarray}
	b(y)&=&\frac{1}{\sqrt{2\pi}}e^{-y^2/2},\\
	\eta&=&\mu,\\
	a(\eta)&=&\mu^2 = \eta^2
\end{eqnarray}

Using Eq.~\ref{eqn:exponential_hypo}, our hypothesis shoud assume
\begin{eqnarray}
	h(x, \theta) &=& \frac{d}{d\eta}(\eta^2/2)\\
		     &=& \eta\\
		     &=& \mu
\end{eqnarray}
To recap what has happened this section, we started with an assumption of the distribution of an observable $y\sim\mathcal N(\mu, 1)$, and then confirmed that it belongs to the exponential family by simply rearrange some terms. Then following Eq.~\ref{eqn:exponential_hypo}, we found that the hypothesis must assume $h(x, \theta)=\eta$ when written in terms of $\eta$. In particular for Gassian, $\eta$ is equivalent to the mean of the distribution, so what we learn from this exercises is that the hypothesis much agrees with the average of $y$. We are still free to choose whatever $h(x, \theta)$ that is theoretically possible. Apparently, not much was gained from this exercises. But it's not the case for other distributions (See Section.~\ref{sec:Bounoulli}.

Before we move on to show the power of this analysis, let's consider a slightly more general case when we starts from $\mathcal N(\mu, \sigma^2)$ with $\sigma$ known. Of course, this can be reduced to the earlier case by scaling $y$ with $\sigma$. More formally, we would relax the requirement of exponential family such that the coupling term is $e^{\eta T(y)}$. Earlier, $T(y) = y$. Following the same procedure that led to Eq.~\ref{eqn:average}, we have
\begin{equation}
	\langle T(y)\rangle = \frac{\partial}{\partial}a(\eta).
\end{equation}
So our hypothesis must satisfy the functional form arising from this equation. In terms of $\mathcal N(\mu, \sigma)$, it turns out $T(y) = y/\sigma$, $\eta = \mu/\sigma$ and $a(\eta) = \eta^2/2$. Since our hypothesis $h(x, \theta)$ should be the same as $\langle y\rangle$, it follows $\langle T(y)\rangle = h(x, \theta)/\sigma = \eta$ and we recover the same thing as before.

A further generalization is to assume $\mathcal N(\mu, \sigma)$ with both $\mu$ and $\sigma$ unknown. The definition of exponential family can be further extended to have as the coupling term $e^{\vec\eta\cdot\vec T(y)}$. Here, the observable $T(y)$ and the parameter $\eta$ become vectors. And Eq.~\ref{eqn:average} becomes
\begin{equation}
	\langle T(y)_i \rangle =-\frac{\partial}{\partial\eta_i}a(\vec\eta)\label{eqn:averageGeneral}
\end{equation}
As for Gassuian, $\vec\eta=(\mu/\sigma^2, -1/2\sigma^2)^T$ and $a(\vec\eta)=-\eta_1^2/4\eta_2+(1/2)\ln\left|1/2\eta_2\right|$. Following Eq.~\ref{eqn:averageGeneral}, the hypothesis should ensure that $\langle y\rangle = \mu$ and $\langle y^2\rangle = \sigma^2 + \mu^2$. Again, not very informativel. But it explains why we would want $y = h(x, \theta) + \mathcal N(\mu, \sigma)$.


\section{Bernoulli and logistic}\label{sec:Bounoulli}
The Bernoulli distribution is a natural choice to describe the probablity of a binary outcome $y$. Here, we believe that $y$ assumes either 1 or 0 with the following probability:
\begin{equation}
	\text{Prob}(y)=\begin{cases}
				\phi, & y = 1\\
				1-\phi, & y = 0
			\end{cases}
\end{equation}
Apparently, we don't know $\phi$ and how to estimate it from our features, but as before, we wonder if something could be deduced realizing that Bernoulli distribution belongs to the exponential family.

First of all, we rewrite the probability mass function in terms of Eq.~\ref{eqn:exponential-family}.
\begin{eqnarray}
	\text{Prob}(y) &=& \phi^y(1-\phi)^{1-y},\\
		     &=& \exp\{y\ln\phi + (1-y)\ln(1-\phi)\}\\
	      &=&e^{y\ln\left(\frac{\phi}{1-\phi}\right)}e^{\ln(1-\phi)}.
\end{eqnarray}
Indeed, Bernoulli distribution can be cast into a form conforming with the definition of exponential family with
\begin{eqnarray}
	b(y) &=& 1,\\
	\eta &=& \ln\frac{\phi}{1-\phi},\\\label{eqn:logit}
	a(\eta) &=& -\ln(1-\phi) = \ln\left(1+e^\eta\right).\label{eqn:BernoulliLogP}
\end{eqnarray}
Following the idea used in the previous section, the expectation of $y$ is given by Eq.~\ref{eqn:average}, or,
\begin{equation}
	\phi = \langle y\rangle = \frac{e^\eta}{1+e^\eta}.\label{eqn:sigmoid}
\end{equation}
Here we used the fact that the average of $y$ is $\phi$ since our starting point is $y\sim\text{Bernoulli}(\phi)$. This equation tells us that the parameter $\phi$ has to be calcuated from a sigmoidal function of $\eta$. There are different hypothesis of $\eta$, for example, $\eta = \vec\theta\cdot\vec x$, but Eq.~\ref{eqn:sigmoid} has to be used to get $\phi$ from $\eta$. This is in contrast with Gaussian. In that case, $\eta$ turns out to be $\mu$, and there is no functional constraints between the two.

Eq.~\ref{eqn:sigmoid} is very powerful. Among all the smooth approximations of step function, this function is chosen by merely invoking some fundamental properties of statistical distribution and inference, namely, (i) the distribution of the observalbe belongs to the exponential family, and (ii) the hypothesis should agreen with the expectation of the observable. Suppose we choose another function to replace Eq.~\ref{eqn:sigmoid}, we wouldn't be able to justify it purely based on the the two properties we just used to reach Eq.~\ref{eqn:sigmoid}.

It may seem a little magic at the first sight, but it actually makes sens. Eq.~\ref{eqn:sigmoid} assumes a fractional form, namely $\phi = \mathcal P/1 + \mathcal P$ where $\mathcal P$ is some unknown function of the features. Being a Bernoulli process, the probability of an outcome should be determined by its associated probability as a fraction of the sum of all possible outcomes' probabilities. This is also the key idea behind Bayesian. From this point of view, Eq.~\ref{eqn:sigmoid} is not that strong a conclusion.
\section{Multinomial}
As another example, let's consider a multinomial distribution problem, where we want to predict the outcome of a multi-choice classification experiment. As usual, we know that the probability of observing a particular outcome $i\in [1,\cdots,n]$ is $\phi_i$ and the purpose is to find out the structure of $\phi_i$. We write the probability in terms of a vector $\vec y$ with $y_j = \delta_{ji}$ if the outcome is $j$, 
\begin{eqnarray}
\text{Prob}(\vec y)&=&\phi_1^{y_1}\cdots\phi_n^{y_n},\\
		   &=&\phi_1^{y_1}\cdots\phi_{n-1}^{y_{n-1}}\phi_n^{y_n},\\
		   &=&\phi_1^{y_1}\cdots\phi_{n-1}^{y_{n-1}}(1-\sum_{i<n}\phi_i)^{y_n},
\end{eqnarray}
where we used the fact that $\phi_i$'s sum to unity. But if we would like to follow the idea that lead to Eq.~\ref{eqn:BernoulliLogP}, we should further write $y_n$ in terms of $y_i$ with $i<n$ and try to convert the expression to Eq.~\ref{eqn:exponential-family}:
\begin{eqnarray}
\text{Prob}(\vec y)&=&\phi_1^{y_1}\cdots\phi_{n-1}^{y_{n-1}}(1-\sum_{i<n}\phi_i)^{1-\sum_{i<n}y_i},\\
		   &=&e^{y_1\ln\phi_1}\cdots e^{y_{n-1}\ln\phi_{n-1}}e^{(1-\sum_{i<n}y_i)\ln(1-\sum_{i<n}\phi_i)},\\
		   &=&e^{y_1\ln(\phi_1/\phi_n)}\cdots e^{y_{n-1}\ln(\phi_{n-1}/\phi_n)}e^{\ln\phi_n}.
\end{eqnarray}
Here, we use $\phi_n$ to denote $1-\sum_{i<n}\phi_i$ just for convenience. Apparently, we can recover the exponential family distribution by setting
\begin{eqnarray}
b(\vec y) &=& 1,\\
\eta_i &=&\ln(\phi_i/\phi_n)=\ln\frac{\phi_i}{1-\sum_{i<n}\phi_i},\\
a(\eta) &=&\ln(1/\phi_n)= \ln\frac{1}{1-\sum_{i<n}\phi_i}.
\end{eqnarray}
In order to use Eq.~\ref{eqn:averageGeneral}, we need to write $a(\eta)$ in terms of $\eta$ or use the chain rule. Let's try to do the former. Since $\eta_i=\ln(\phi_i/\phi_n)$, we have $\phi_i=\phi_ne^\eta_i$ and
\begin{eqnarray}
\sum_{i<n}\phi_i &=& \sum_{i<n}\phi_ne^{\eta_i},\\
		 &=& \phi_n\sum_{i<n}e^{\eta_i},\\
		 &=& \left(1-\sum_{i<n}\phi_i\right)\sum_{i<n}e^{\eta_i},\\
\sum_{i<n}\phi_i&=&\frac{\sum_{i<n}e^{\eta_i}}{1+\sum_{i<n}e^{\eta_i}},\\
a(\eta)&=&\ln\left(1+\sum_{i<n}e^{\eta_i}\right)
\end{eqnarray}

By using Eq.~\ref{eqn:averageGeneral}, one has the structure of $\phi_i$ in terms of $\eta_i$,
\begin{eqnarray}
\phi_i &=&\langle y_i\rangle\\
       &=&\frac{\partial a(\vec\eta)}{\partial\eta_i},\\
       &=&\frac{e^{\eta_i}}{1+\sum_{i<n}e^{\eta_i}}
\end{eqnarray}
Here, $i\in[1,\cdots,n-1]$, and $\phi_n=1/(1+\sum_{i<n}e^{\eta_i})$. Given the discussion at the end of the previous section, this result is not that surprising.

